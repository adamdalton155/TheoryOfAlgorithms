{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "381452e5",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">The Polynomial Time Complexity Class (P)</h1>\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab94606",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">What is Time Complexity?</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc7e1b43",
   "metadata": {},
   "source": [
    "In computer science, time complexity can be described as the theory of computation that studies the resources and cost of the computation required to solve a computational problem. Furthermore, complexity theory also analyzes the difficulty of the problem in terms of various computational resources. An example of this is mowing grass. This task has a linear complexity as it takes double the time to mow double the area. However, looking up a word in a dictionary has logarithmic complexity because if you start in the exactly in the middle, the problem is reduced to the half where the word is. Time complexity is often estimated by counting the number of operations to complete the algorithm supposing that each step takes a fixed amount of execution time. The algorithm (the steps followed) is a set of instructions to solve a problem. Based on this, the instructions are given to a computer to execute said algorithm. The steps can be defined in number of different ways and can also depend on the programming language used to perform the operation due to varying syntax and performance of the language chosen. The performance of the algorithm will also vary depending on the operating system, hardware, software, method used etc.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10b8f7d1",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">Measuring Time Complexity</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05f09325",
   "metadata": {},
   "source": [
    "How we go about measuring time complexity is with Big O Notation. Big O Notation is the language we used to describe the time complexity of an algorithm, compare the efficiency and to make decisions about how we solve a problem. Under the umbrella term Big O notation, there are sub categories that are important to understand as well so we can understand where polynomial time fits in.\n",
    "\n",
    " -  The first one we will look at is Constant Time Complexity O(<sup>1</sup>). When the time complexity is constant, the size of input <i>N</i> doesnt matter. An algorithm with a constant time complexity takes a constant amount of time to run, regardless of the size of the input n, because of this, Constant Time Complexity is one of te fastest algorithms out there. An example of this is printing out Hello World. Printing out that statement has a Constant Time Complexity because the number of operations to complete is always 1. It's important to ensure that there are no loops, recursion or non-constant time functions as this can result in a different time complexity.\n",
    "\n",
    " - The second time complexity is Linear Time Complexity O(<sup>n</sup>). This occurs when the time complexity grows in direct relation to the size of the input <i>N</i>. The input is processed in <i>N</i> number of operations meaning the bigger the input, the longer the algorithm will take to complete. This is generally used when the problem requires us to look at every item in a list e.g. finding the maximum value. A more real world example if we are trying to find a book on a shelf, we have to check each book individually to find the one we are looking for.\n",
    "\n",
    " - The third time complexity we must look at is Logarithmic Time O(log <sup>n</sup>). The purpose of this is to reduce the size of the operations while the size of the input increases. This is generally found on binary search functions or binary trees. A binary tree is an array of elements split in two (hence the name binary) and then starting to search within that split. The result of doing this makes sure that the operation is not performed on every element of the list.\n",
    "\n",
    " - Finally we will discuss Quadratic Time Complexity O(n<sup>2</sup>). Also known as an algorithm with a non-linear time complexity, meaning the running time increases non-linearly (n<sup>2</sup>) depending on the length of the input. Usually found in nested for loops (a for loop inside a for loop) then the time complexity can be represented as O(<sup>n</sup>)*O(<sup>n</sup>) = O(n<sup>2</sup>).\n",
    "\n",
    "<h3 style=\"color: blue;\">Worst, Average and Best case scenarios</h3>\n",
    "\n",
    "When measuring the time complexity and also the efficiency of an algorithm, we must also understand the worst, average and best case scenarios for an algorithm. To start...\n",
    " - For worst case scenario (most used), we calculate the highest possbile run-time for an algorithm. To do this we must know the maximum operations needed to complete. An example of this if we are performing a linear search for a value that happens to the last element in a list and we are checking one element at a time starting at the position 0 (the start) then this will take the longest time to complete making it the worst case scenairo.\n",
    "\n",
    " - Average case scenario (rarely used) occurs when we take all of the possible inputs and calculate the computing time for all of the inputs, then sum of all calculated values and divide by the total number of inputs. The reason it is rarely used is simply that its not very practical as we must know (or at least try and predict) the distribution of all of the possible inputs.\n",
    "\n",
    " - Finally we have best case scenario (very rarely used). For best case, we must calculate the lower bound of the run-time of an algorithm. We must also know what causes the least number of operations to be executed. Going back to the linear search problem, the best case scenario would occur when searching for an element in a list, just so happens to be at position 0 or the start of the list. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "000d9685",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">NP-Complete Problems also known as Non-Deterministic Polynomial</h2>\n",
    "An NP-Complete Problem is any class of computational problem that has no efficient algorithm to solve the problem. An example of an NP-Complete problem is the <a href=\"https://www.britannica.com/science/traveling-salesman-problem\">travelling salesman problem.</a> A problem is considered Non-Deterministic Polynomial if the solution can be gussed and verified in polynomial time and non-deterministic means that there is now a particular rule that is followed to make said guess. This implies that finding an NP-Complete problem with an efficient algorithm can be found for all such problems because any problem in this class can be re-used and applied to any other problem in this class. Currently, it is not known if any polynomial time algorithms will ever be found for NP-Complete problems. The reason for trying to find polynomial time algorithms is that it's considered efficient in comparison to exponential algorithms. For exponential, the execution time grows rapidly as the size of the problem increases. By combining what we now know, we can now start to understand polynomial time, and how it works and compares to other algorithms.\n",
    "\n",
    " First of all we would like to show polynomial time in graph form. To have a visual representation of the time complexity compared to exponential is useful. Below is a graph with two lines showing how both handle the same inputs. It may also be useful to change the values around to see how it does change and just how much the inputs do have an impact. Polynomial is represented by the blue line and exponential is the orange line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ad58aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Numbers.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Plotting.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Numbers.\n",
    "import numpy as np\n",
    "# Plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a figure.\n",
    "fig, ax = plt.subplots(figsize = (14,7))\n",
    "# x values.\n",
    "x = np.linspace (0.0, 12.0, 1000)\n",
    "# Plot polynomial.\n",
    "ax.plot(x, x**2, label = \"$x^2$\")\n",
    "# Plot exponential.\n",
    "ax.plot(x, 2**x, label = \"$2^x$\")\n",
    "# Legend.\n",
    "ax.legend()\n",
    "# Show.\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "891e4d1b",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">Polynomial time complexity O(n<sup>c</sup>)</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "300b2a8d",
   "metadata": {},
   "source": [
    "To start, if an algorithm is making polynomial calls to a function that has been implemented as a polynomial algorithm, then that algorithm also has polynomial time-complexity. This helps us to understand polynomial algorithms as you don't have to keep track of individual complexity of sub-routines as long as they are polynomial. Also, if an algorithm can in fact be solved in polynomial time, than the time complexity is called complexity class P. An interesting fact we came across during our research is that the Clay Mathematics Institute will award $1,000,000 to the person who proves that P=NP. For context, no polynomial algorithm as of now is considered NP complete but on the flip side, none haven't been proven to not be NP complete so polynoimal time seems to be stuck on this limbo and doesn't belong to either camp. As mentioned earlier, the travelling salesman algorithm is an example of this. Under the term polynomial time, there are two ways to solve a polynomial algorithm.\n",
    "   \n",
    "    - Brute force: Solving an algorithm by brute force means we solve the problem through exhaustion. We go through every possible choice until a solution is found. The time complexity for this usually corrolates with the size of the input meaning the algorithm does work but is usually slow. An example of this is the Quick Sort algorithm. It's considered brute force because first we must divide the partition and then and then sort each element in the array which means we go through every possible choice\n",
    "\n",
    "    - Dynamic Programming: This refers to simplifying a problem by breaking it down into smaller problems in a recursive manner. When applied in computer science, if the problem can be applied by breaking down into smaller problems, then finding the optimal solution to the smaller problems, then it is said to have an optiaml substructure. When applied to polynomial algorithms, there is a technicality we must look at. That being dynamic programming falls under Pseduo-polynomial algorithms. These types of algorithms are where the worst-case time complexity is polynomial in the value of in the input as opposed to the number of inputs. An example of this is the Knapsack problem. This problem based on a particular stack of objects and each having a weight and value. So we must select the number of elements to include in a stack in a way that the total weight of these objects is less than or equal to a set limit. \n",
    "    \n",
    "Below are examples of a brute force algorithm (quick sort) and a dynamic programming algorithm (Pseduo-polynomial).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7173d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsorted Array\n",
      "[1, 7, 4, 1, 10, 9, -2]\n",
      "Sorted Array in Ascending Order:\n",
      "[-2, 1, 1, 4, 7, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "#Quick sort\n",
    "\n",
    "def partition(array, low, high):\n",
    " \n",
    "    # choose the rightmost element as pivot\n",
    "    pivot = array[high]\n",
    " \n",
    "    # pointer for greater element\n",
    "    i = low - 1\n",
    " \n",
    "    # traverse through all elements\n",
    "    # compare each element with pivot\n",
    "    for j in range(low, high):\n",
    "        if array[j] <= pivot:\n",
    " \n",
    "            # If element smaller than pivot is found\n",
    "            # swap it with the greater element pointed by i\n",
    "            i = i + 1\n",
    " \n",
    "            # Swapping element at i with element at j\n",
    "            (array[i], array[j]) = (array[j], array[i])\n",
    " \n",
    "    # Swap the pivot element with the greater element specified by i\n",
    "    (array[i + 1], array[high]) = (array[high], array[i + 1])\n",
    " \n",
    "    # Return the position from where partition is done\n",
    "    return i + 1\n",
    " \n",
    "# function to perform quicksort\n",
    " \n",
    " \n",
    "def quickSort(array, low, high):\n",
    "    if low < high:\n",
    " \n",
    "        # Find pivot element such that\n",
    "        # element smaller than pivot are on the left\n",
    "        # element greater than pivot are on the right\n",
    "        pi = partition(array, low, high)\n",
    " \n",
    "        # Recursive call on the left of pivot\n",
    "        quickSort(array, low, pi - 1)\n",
    " \n",
    "        # Recursive call on the right of pivot\n",
    "        quickSort(array, pi + 1, high)\n",
    " \n",
    " \n",
    "data = [1, 7, 4, 1, 10, 9, -2]\n",
    "print(\"Unsorted Array\")\n",
    "print(data)\n",
    " \n",
    "size = len(data)\n",
    " \n",
    "quickSort(data, 0, size - 1)\n",
    " \n",
    "print('Sorted Array in Ascending Order:')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5430d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "def knapSack(W, wt, val, n): \n",
    "    K = [[0 for x in range(W + 1)] for x in range(n + 1)] \n",
    "   \n",
    "    # Build table K[][] in bottom up manner \n",
    "    for i in range(n + 1): \n",
    "        for w in range(W + 1): \n",
    "            if i == 0 or w == 0: \n",
    "                K[i][w] = 0\n",
    "            elif wt[i-1] <= w: \n",
    "                K[i][w] = max(val[i-1] \n",
    "                          + K[i-1][w-wt[i-1]],   \n",
    "                              K[i-1][w]) \n",
    "            else: \n",
    "                K[i][w] = K[i-1][w] \n",
    "   \n",
    "    return K[n][W] \n",
    "   \n",
    "   \n",
    "# Driver code \n",
    "val = [60, 100, 120] \n",
    "wt = [10, 20, 30] \n",
    "W = 50\n",
    "n = len(val) \n",
    "print(knapSack(W, wt, val, n)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b0b0473",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">Applications of polynomial time in the real world</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "647af824",
   "metadata": {},
   "source": [
    "Polynomial time algorithms are used in various fields for real world applications. For instance, polynomial algorithms are used in practical cryptography. Say if an organization has a system that in theory takes one hundred years to hack. In reality, this would depend on the hardware or the budget. What if somehow a quantum computer was used. It is actually quite difficult to estimate how long it would take to crack. If we considered a cryptosystem which depends on a parameter n that could potentially run for infinity, we analyze the security of the cryptosystem in terms of the time complexity of breakng it. \n",
    "\n",
    "The time complexity doesn't neccessarily depend on the hardware (unless performed by a quantum computer) because regardless of hardware, the time to break is still O(2<sup>n</sup>). So when we look at the system that this organization has, if the system cannot be hacked in polynomial time, we can say that yes the system is technically secure as it cannot be broken in what is considered to be an optimal time and is rather in exponential time which is seen as  slow/worst case. On the flip side can we really prove that a system is secure if it can be hacked, even if it is slow to break?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "938fdc5a",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">Turing Machines</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4cf1a44",
   "metadata": {},
   "source": [
    "In 1936, Alan Turing gave the first definition of an algorithm in the form of a Turing Machine. He wanted this algorithm to be clear, simple and most of all efficient (polynomial). Turing Machines, as described by Alan Turing are simple abstract computational devices intended to help investigate the extent and limitations of what can be computed. Although back in 1936, he named them 'Automatic Machines'. In short, a turing machine consists of a two way infinite tape and a finite state control. The tape is divided up into sqaures, each holds a symbol from an alphabet (we will discuss alphabet later) that also includes the blank symbol. The machine has a read/write state. The machine is also connected to the control that scans the tape. Depending on the state that is scanned, the turing machine will make a move, consisting of...\n",
    "\n",
    " - Printing a symbol\n",
    " - Moving the head left or right one square\n",
    " - Assuming a new state\n",
    "\n",
    " Initally the tape is blank, except from the input string over the finite alphabet Σ; and the head will start by pointing to the most left symbol of the input. We can specify a turing machine <i>M</i> by giving the following \n",
    " - Σ (a finite input alphabet).\n",
    " - Γ(a finite tape alphabet). Σ ⊆ Γ./b ∈ Γ −Σ.\n",
    " - Q (a finite set of states). There are 3 special states:\n",
    "\n",
    "    – q 0 (the initial state)\n",
    "\n",
    "    – q accept (the state in which M halts and accepts) \n",
    "\n",
    "    – q reject (the state in which M halts and rejects)\n",
    "    \n",
    "The turing machine <i>M</i> works by starting with an input string X, which appears on the tape and on both sides has infinitely many blanks with the head pointing to the leftmost symbol of X. The turing machine <i>M</i> moves according to the transition function and may run forever unless it halts in either an accept or reject state. To understand turing machines we must also understand the language of turing machines. In short, language in relation to a turing machine is the set of all strings that a turing machine will accept. For example, if we were to construct a language L = {0n1n2n}, the turing machine will only use either a 0, 1 or 2 as the language that it understands. <a href=\"https://www.javatpoint.com/examples-of-turing-machine\">This example uses this language and explains in depth the steps to perfrorm the computation</a>. The purpose of turing machines was originally to formalize the idea of computability to determine how to tackle a mathemcatical problem. Today, through Alan Turing's work, there is an understanding that for any computable problem that exists, a turing machine can be designed that will compute it. On the other side of this, any problem that is not computable by a turing machine, cannot be computed by any finite means possible. The Turing Machine is so important because they are considered to be one of the foundational models of computability and (theoretical) computer science. It is so important to discuss a turing machine espicially when discussing polynomial time because polynomial is about solving problems in the most efficient way possible and turing machines prove if a problem can even be solved in the first place. Below is a python implementation of a turing machine. You can adjust the list's (laguage) values to see the different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160bb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0110101\n",
      "0X110101\n",
      "01Y10101\n",
      "011X0101\n",
      "0110X101\n",
      "01101Y01\n",
      "011010Y1\n",
      "0110101X_\n",
      "0110101_T_\n"
     ]
    }
   ],
   "source": [
    "# State table.\n",
    "table = {\n",
    "    ('X', '_'): ['_', 'R', 'T'],\n",
    "    ('X', '0'): ['0', 'R', 'X'],\n",
    "    ('X', '1'): ['1', 'R', 'Y'],\n",
    "    ('Y', '_'): ['_', 'R', 'F'],\n",
    "    ('Y', '0'): ['0', 'R', 'Y'],\n",
    "    ('Y', '1'): ['1', 'R', 'X'],\n",
    "}\n",
    "\n",
    "# Tape input.\n",
    "tape = list('0110101')\n",
    "# Position on tape.\n",
    "pos = 0\n",
    "# Initial state is first in table.\n",
    "state = 'X'\n",
    "\n",
    "# Keep going while we are not in a halting state.\n",
    "while state not in ['T', 'F']:\n",
    "    # Print the current status.\n",
    "    print(''.join(tape[:pos]) + state + ''.join(tape[pos:]))\n",
    "    # Get the row of the table.\n",
    "    row = table[(state, tape[pos])]\n",
    "    # Overwrite the symbol.\n",
    "    tape[pos] = row[0]\n",
    "    # Move left or right.\n",
    "    if row[1] == 'R':\n",
    "        # Put blanks on tape as necessary.\n",
    "        if pos == len(tape) - 1:\n",
    "            tape = tape + ['_']\n",
    "        # Increase position.\n",
    "        pos = pos + 1\n",
    "    else:\n",
    "        # Put blanks on tape as necessary.\n",
    "        if pos == 0:\n",
    "            tape = ['_'] + tape\n",
    "            # The position on the tape has to move with it.\n",
    "            pos = pos + 1\n",
    "        # Decrease position.\n",
    "        pos = pos - 1\n",
    "    # Update the state.\n",
    "    state = row[2]\n",
    "\n",
    "# Print the current status.\n",
    "print(''.join(tape[:pos]) + state + ''.join(tape[pos:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f176395ce4c2304b497421fb1866b077f3f965c24f63e7824eefa3a7d41c927c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
