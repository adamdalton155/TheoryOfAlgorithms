{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "381452e5",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">The Polynomial Time Complexity Class (P)</h1>\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab94606",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">What is Time Complexity?</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc7e1b43",
   "metadata": {},
   "source": [
    "In computer science, time complexity can be described as the theory of computation that studies the resources and cost of the computation required to solve a computational problem. Furthermore, complexity theory also analyzes the difficulty of the problem in terms of various computational resources. An example of this is mowing grass. This task has a linear complexity as it takes double the time to mow double the area. However, looking up a word in a dictionary has logarithmic complexity because if you start in the exactly in the middle, the problem is reduced to the half where the word is. Time complexity is often estimated by counting the number of operations to complete the algorithm supposing that each step takes a fixed amount of execution time. The algorithm (the steps followed) is a set of instructions to solve a problem. Based on this, the instructions are given to a computer to execute said algorithm. The steps can be defined in number of different ways and can also depend on the programming language used to perform the operation due to varying syntax and performance of the language chosen. The performance of the algorithm will also vary depending on the operating system, hardware, software, method used etc.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10b8f7d1",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">Measuring Time Complexity</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05f09325",
   "metadata": {},
   "source": [
    "How we go about measuring time complexity is with Big O Notation. Big O Notation is the language we used to describe the time complexity of an algorithm, compare the efficiency and to make decisions about how we solve a problem. Under the umbrella term Big O notation, there are sub categories that are important to understand as well so we can understand where polynomial time fits in.\n",
    "\n",
    " -  The first one we will look at is Constant Time Complexity O(1). When the time complexity is constant, the size of input (n) doesnt matter. An algorithm with a constant time complexity takes a constant amount of time to run, regardless of the size of the input n, because of this, Constant Time Complexity is one of te fastest algorithms out there. An example of this is printing out Hello World. Printing out that statement has a Constant Time Complexity because the number of operations to complete is always 1. It's important to ensure that there are no loops, recursion or non-constant time functions as this can result in a different time complexity.\n",
    "\n",
    " - The second time complexity is Linear Time Complexity O(n). This occurs when the time complexity grows in direct relation to the size of the input n. The input is processed in n number of operations meaning the bigger the input, the longer the algorithm will take to complete. This is generally used when the problem requires us to look at every item in a list e.g. finding the maximum value. A more real world example if we are trying to find a book on a shelf, we have to check each book individually to find the one we are looking for.\n",
    "\n",
    " - The third time complexity we must look at is Logarithmic Time O(log n). The purpose of this is to reduce the size of the operations while the size of the input increases. This is generally found on binary search functions or binary trees. A binary tree is an array of elements split in two (hence the name binary) and then starting to search within that split. The result of doing this makes sure that the operation is not performed on every element of the list.\n",
    "\n",
    " - Finally we will discuss Quadratic Time Complexity O(n^2). Also known as an algorithm with a non-linear time complexity, meaning the running time increases non-linearly (n^2) depending on the length of the input. Usually found in nested for loops (a for loop inside a for loop) then the time complexity can be represented as O(n)*O(n) = O(n^2).\n",
    "\n",
    "<h3 style=\"color: blue;\">Worst, Average and Best case scenarios</h3>\n",
    "\n",
    "When measuring the time complexity and also the efficiency of an algorithm, we must also understand the worst, average and best case scenarios for an algorithm. To start...\n",
    " - For worst case scenario (most used), we calculate the highest possbile run-time for an algorithm. To do this we must know the maximum operations needed to complete. An example of this if we are performing a linear search for a value that happens to the last element in a list and we are checking one element at a time starting at the position 0 (the start) then this will take the longest time to complete making it the worst case scenairo.\n",
    "\n",
    " - Average case scenario (rarely used) occurs when we take all of the possible inputs and calculate the computing time for all of the inputs, then sum of all calculated values and divide by the total number of inputs. The reason it is rarely used is simply that its not very practical as we must know (or at least try and predict) the distribution of all of the possible inputs.\n",
    "\n",
    " - Finally we have best case scenario (very rarely used). For best case, we must calculate the lower bound of the run-time of an algorithm. We must also know what causes the least number of operations to be executed. Going back to the linear search problem, the best case scenario would occur when searching for an element in a list, just so happens to be at position 0 or the start of the list. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "000d9685",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">NP-Complete Problems also known as Non-Deterministic Polynomial</h2>\n",
    "An NP-Complete Problem is any class of computational problem that has no efficient algorithm to solve the problem. An example of an NP-Complete problem is the <a href=\"https://www.britannica.com/science/traveling-salesman-problem\">travelling salesman problem.</a> A problem is considered Non-Deterministic Polynomial if the solution can be gussed and verified in polynomial time and non-deterministic means that there is now a particular rule that is followed to make said guess. This implies that finding an NP-Complete problem with an efficient algorithm can be found for all such problems because any problem in this class can be reused and applied to any other problem in this class. Currently, it is not known if any polynomial-time algorithms will ever be found for NP-Complete problems. The reason for trying to find polynomial-time algorithms is that it's considered efficient in comparison to exponential algorithms. For exponential, the execution time grows rapidly as the size of the problem increases. By combining what we now know, we can now start to understand polynomial time, and how it works and compares to other algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "891e4d1b",
   "metadata": {},
   "source": [
    "<h2 style=\"color: blue;\">Polynomial time complexity O(n^c)</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "300b2a8d",
   "metadata": {},
   "source": [
    "To start, if an algorithm is making polynomial calls to a function that has been implemented as a polynomial algorithm, then that algorithm also has polynomial time-complexity. This helps us to understand polynomial algorithms as you don't have to keep track of individual complexity of sub-routines as long as they are polynomial. Also, if an algorithm can in fact be solved in polynomial time, than the time complexity is called complexity class P. An interesting fact we came across during our research is that the Clay Mathematics Institute will award $1,000,000 to the person who proves that P=NP. For context, no polynomial algorithm as of now is considered NP complete but on the flip side, none haven't been proven to not be NP complete so polynoimal time seems to be stuck on this limbo and doesn't belong to either camp. As mentioned earlier, the travelling salesman algorithm is an example of this. Under the term polynomial time, there are two ways to solve a polynomial algorithm.\n",
    "   \n",
    "    - Brute force: Solving an algorithm by brute force means we solve the problem through exhaustion. We go through every possible choice until a solution is found. The time complexity for this usually corrolates with the size of the input meaning the algorithm does work but is usually slow. An example of this is the Quick Sort algorithm. It's considered brute force because first we must divide the partition and then and then sort each element in the array which means we go through every possible choice\n",
    "\n",
    "    - Dynamic Programming: This refers to simplifying a problem by breaking it down into smaller problems in a recursive manner. When applied in computer science, if the problem can be applied by breaking down into smaller problems, then finding the optimal solution to the smaller problems, then it is said to have an optiaml substructure. When applied to polynomial algorithms, there is a technicality we must look at. That being dynamic programming falls under Pseduo-polynomial algorithms. An exmaple of this is the Knapsack problem. \n",
    "Below are examples of a brute force algorithm (quick sort) and a dynamic programming algorithm ().\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7173d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsorted Array\n",
      "[1, 7, 4, 1, 10, 9, -2]\n",
      "Sorted Array in Ascending Order:\n",
      "[-2, 1, 1, 4, 7, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "def partition(array, low, high):\n",
    " \n",
    "    # choose the rightmost element as pivot\n",
    "    pivot = array[high]\n",
    " \n",
    "    # pointer for greater element\n",
    "    i = low - 1\n",
    " \n",
    "    # traverse through all elements\n",
    "    # compare each element with pivot\n",
    "    for j in range(low, high):\n",
    "        if array[j] <= pivot:\n",
    " \n",
    "            # If element smaller than pivot is found\n",
    "            # swap it with the greater element pointed by i\n",
    "            i = i + 1\n",
    " \n",
    "            # Swapping element at i with element at j\n",
    "            (array[i], array[j]) = (array[j], array[i])\n",
    " \n",
    "    # Swap the pivot element with the greater element specified by i\n",
    "    (array[i + 1], array[high]) = (array[high], array[i + 1])\n",
    " \n",
    "    # Return the position from where partition is done\n",
    "    return i + 1\n",
    " \n",
    "# function to perform quicksort\n",
    " \n",
    " \n",
    "def quickSort(array, low, high):\n",
    "    if low < high:\n",
    " \n",
    "        # Find pivot element such that\n",
    "        # element smaller than pivot are on the left\n",
    "        # element greater than pivot are on the right\n",
    "        pi = partition(array, low, high)\n",
    " \n",
    "        # Recursive call on the left of pivot\n",
    "        quickSort(array, low, pi - 1)\n",
    " \n",
    "        # Recursive call on the right of pivot\n",
    "        quickSort(array, pi + 1, high)\n",
    " \n",
    " \n",
    "data = [1, 7, 4, 1, 10, 9, -2]\n",
    "print(\"Unsorted Array\")\n",
    "print(data)\n",
    " \n",
    "size = len(data)\n",
    " \n",
    "quickSort(data, 0, size - 1)\n",
    " \n",
    "print('Sorted Array in Ascending Order:')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5430d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f176395ce4c2304b497421fb1866b077f3f965c24f63e7824eefa3a7d41c927c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
